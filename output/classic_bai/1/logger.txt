Static J Initialized with J=2000000
所有手臂均值： [0.02 0.04 0.06 0.08 0.1 ]
所有手臂真实概率p： [0.4453 0.3086 0.4832 0.4451 0.4401]
所有手臂真实奖励mu： [0.0449 0.1296 0.1242 0.1797 0.2272]
epsilon-贪婪算法的累积懊悔为： 12.299999999999969
Futurity Mechanism激发次数 0
UCB算法的累积懊悔为： 95.06000000000067
Futurity Mechanism激发次数 0
Thompson Sampling算法的累积懊悔为： 36.63999999999988
Futurity Mechanism激发次数 0
Gaussian TS算法的累积懊悔为： 122.84000000000103
Futurity Mechanism激发次数 0
Exponential TS算法的累积懊悔为： 13.219999999999908
Futurity Mechanism激发次数 0
Poisson TS算法的累积懊悔为： 37.23999999999987
Futurity Mechanism激发次数 0


self.mu_times_p = np.array(range(1, K+1))/K/10  # Mean reward probabilities for each arm
# Initialize arms and their corresponding Bernoulli reward probabilities
# self.mu = 0.5 + np.array(range(1, K+1))/3  # Mean reward probabilities for each arm
self.p = 0.5+np.random.uniform(size=K)/3   # Actual probabilities for each arm
self.mu = self.mu_times_p / self.p  # Mean reward probabilities for each arm


epsilon=0.05
coef = 1