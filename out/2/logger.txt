Static J Initialized with J=500000
所有手臂均值： [0.04 0.08 0.12 0.16 0.2 ]
所有手臂真实概率p： [0.6453 0.5086 0.6832 0.6451 0.6401]
所有手臂真实奖励mu： [0.062  0.1573 0.1756 0.248  0.3124]
epsilon-贪婪算法的累积懊悔为： 23.51999999999995
Futurity Mechanism激发次数 0
UCB算法的累积懊悔为： 96.48000000000097
Futurity Mechanism激发次数 0
Exponential TS算法的累积懊悔为： 20.91999999999984
Futurity Mechanism激发次数 0
Poisson TS算法的累积懊悔为： 44.91999999999949
Futurity Mechanism激发次数 0

self.mu_times_p = np.array(range(1, K+1))/K/5  # Mean reward probabilities for each arm
# Initialize arms and their corresponding Bernoulli reward probabilities
# self.mu = 0.5 + np.array(range(1, K+1))/3  # Mean reward probabilities for each arm
self.p = 0.5+np.random.uniform(size=K)/3   # Actual probabilities for each arm
self.mu = self.mu_times_p / self.p  # Mean reward probabilities for each arm


epsilon=0.05
coef = 1